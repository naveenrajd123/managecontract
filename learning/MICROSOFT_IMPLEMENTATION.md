# LLM Integration for Data Science Teams â€” Microsoft Ecosystem

**For Interview: Microsoft Data Science/Data Architecture Role**

**Context:** You're joining a data science team at Microsoft that handles **large volumes of data from multiple sources**. They want to explore **integrating LLMs** to unlock value from unstructured data (documents, text, PDFs) that currently sits unused alongside their structured datasets.

**Your Value Proposition:** You've built a real-world LLM integration project that solves a common data problemâ€”extracting structured insights from unstructured documents at scale using RAG, semantic search, and responsible AI practices.

---

## The Data Science Problem (Why LLMs Matter for Data Teams)

### Current State (Before LLM Integration)
```
Data Team's Typical Scenario:
â”œâ”€â”€ Structured Data (20% of total data)
â”‚   â”œâ”€â”€ SQL databases (customer, sales, products)
â”‚   â”œâ”€â”€ Data warehouses (Synapse, Snowflake)
â”‚   â”œâ”€â”€ Analytics pipelines (ADF, Databricks)
â”‚   â””â”€â”€ BI dashboards (Power BI, Tableau)
â”‚   âœ… Fully queryable, analyzable, actionable
â”‚
â””â”€â”€ Unstructured Data (80% of total data)
    â”œâ”€â”€ Contracts, agreements, legal docs
    â”œâ”€â”€ Emails, support tickets
    â”œâ”€â”€ Reports, presentations
    â”œâ”€â”€ Invoices, receipts
    â””â”€â”€ Technical documentation
    âŒ Locked in PDFs/files
    âŒ Not searchable or analyzable
    âŒ Can't join with structured data
    âŒ No insights, no ML features
```

### After LLM Integration
```
Unified Data Architecture:
â”œâ”€â”€ Structured Data (SQL, warehouses)
â”‚   â””â”€â”€ [Existing pipelines continue]
â”‚
â”œâ”€â”€ LLM-Processed Unstructured Data
â”‚   â”œâ”€â”€ Extracted metadata â†’ SQL tables
â”‚   â”œâ”€â”€ Vector embeddings â†’ semantic search
â”‚   â”œâ”€â”€ Summaries/classifications â†’ analytics
â”‚   â””â”€â”€ RAG-powered Q&A â†’ natural language queries
â”‚   âœ… Now queryable alongside structured data
â”‚   âœ… Can join contracts with sales/customer data
â”‚   âœ… New ML features from text
â”‚   âœ… Natural language interface for analysts
â”‚
â””â”€â”€ Analytics Layer
    â””â”€â”€ Combined insights from ALL data sources
```

**This is the value you bring:** Turning "dark data" into structured, queryable, analyzable assets that integrate with existing data infrastructure.

---

## Multi-Source Data Integration Architecture (Microsoft Stack)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES (Multiple)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Structured Sources:                                                    â”‚
â”‚  â”œâ”€â”€ Azure SQL / Postgres / Cosmos DB                                  â”‚
â”‚  â”œâ”€â”€ Dynamics 365 / Power Platform                                     â”‚
â”‚  â”œâ”€â”€ SAP / Salesforce / ServiceNow (via connectors)                   â”‚
â”‚  â””â”€â”€ Internal databases                                                â”‚
â”‚                                                                         â”‚
â”‚  Unstructured Sources:                                                  â”‚
â”‚  â”œâ”€â”€ SharePoint / OneDrive (contracts, docs)                          â”‚
â”‚  â”œâ”€â”€ Blob Storage / ADLS Gen2 (archived files)                        â”‚
â”‚  â”œâ”€â”€ Email (Exchange / Outlook)                                        â”‚
â”‚  â”œâ”€â”€ SFTP / vendor portals                                             â”‚
â”‚  â””â”€â”€ Document repositories                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ORCHESTRATION LAYER (ADF / Synapse Pipelines)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Ingestion:                                                        â”‚
â”‚  â”œâ”€â”€ Scheduled batch loads (hourly/daily)                              â”‚
â”‚  â”œâ”€â”€ Event-driven triggers (new file, new record)                      â”‚
â”‚  â”œâ”€â”€ Change data capture (CDC) from sources                            â”‚
â”‚  â””â”€â”€ API polling / webhooks                                             â”‚
â”‚                                                                         â”‚
â”‚  Routing Logic:                                                         â”‚
â”‚  â”œâ”€â”€ Structured data â†’ SQL/Synapse (existing pipeline)                 â”‚
â”‚  â”œâ”€â”€ Unstructured data â†’ LLM processing pipeline (new)                 â”‚
â”‚  â””â”€â”€ Mixed data â†’ hybrid processing                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STORAGE LAYER (Lakehouse Pattern)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ADLS Gen2 (Data Lake):                                                 â”‚
â”‚  â”œâ”€â”€ /raw (bronze) - ingested files as-is                              â”‚
â”‚  â”œâ”€â”€ /processed (silver) - cleaned, chunked, extracted text            â”‚
â”‚  â””â”€â”€ /curated (gold) - structured data ready for analytics             â”‚
â”‚                                                                         â”‚
â”‚  Azure SQL / Postgres:                                                  â”‚
â”‚  â”œâ”€â”€ Structured metadata tables                                        â”‚
â”‚  â”œâ”€â”€ LLM extraction results                                             â”‚
â”‚  â””â”€â”€ Joins with existing business data                                  â”‚
â”‚                                                                         â”‚
â”‚  Azure AI Search (Vector Store):                                        â”‚
â”‚  â”œâ”€â”€ Text chunks + embeddings                                           â”‚
â”‚  â”œâ”€â”€ Metadata filters (source, date, type, etc.)                       â”‚
â”‚  â””â”€â”€ Hybrid search (vector + keyword + filters)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LLM PROCESSING LAYER (Core AI)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Compute Options:                                                       â”‚
â”‚  â”œâ”€â”€ Azure Functions (lightweight tasks)                                â”‚
â”‚  â”œâ”€â”€ Container Apps / AKS (scalable workers)                            â”‚
â”‚  â””â”€â”€ Databricks (batch processing at scale)                             â”‚
â”‚                                                                         â”‚
â”‚  LLM Tasks:                                                              â”‚
â”‚  â”œâ”€â”€ 1. Text Extraction (PDF â†’ text)                                   â”‚
â”‚  â”œâ”€â”€ 2. Chunking (split documents, overlap)                            â”‚
â”‚  â”œâ”€â”€ 3. Structured Extraction (metadata via LLM prompts)               â”‚
â”‚  â”œâ”€â”€ 4. Classification (risk, category, sentiment)                     â”‚
â”‚  â”œâ”€â”€ 5. Summarization (key points, executive summary)                  â”‚
â”‚  â””â”€â”€ 6. Embedding Generation (text â†’ vectors)                          â”‚
â”‚                                                                         â”‚
â”‚  LLM Provider Options:                                                  â”‚
â”‚  â”œâ”€â”€ Azure OpenAI (GPT-4, embeddings) â† Most common                   â”‚
â”‚  â”œâ”€â”€ OSS models on AKS (Llama, Mistral via vLLM)                      â”‚
â”‚  â””â”€â”€ Azure AI Model Catalog                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ANALYTICS & CONSUMPTION LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Synapse / Fabric Lakehouse:                                            â”‚
â”‚  â”œâ”€â”€ SQL analytics on structured + LLM-extracted data                  â”‚
â”‚  â”œâ”€â”€ Join contracts with sales/customer/product data                   â”‚
â”‚  â””â”€â”€ Time-series analysis, trend detection                              â”‚
â”‚                                                                         â”‚
â”‚  Power BI Dashboards:                                                   â”‚
â”‚  â”œâ”€â”€ Contract risk distribution                                         â”‚
â”‚  â”œâ”€â”€ Renewal timelines                                                  â”‚
â”‚  â”œâ”€â”€ Vendor/partner analytics                                           â”‚
â”‚  â””â”€â”€ Custom KPIs from LLM-extracted fields                              â”‚
â”‚                                                                         â”‚
â”‚  RAG-Powered Q&A Interface:                                             â”‚
â”‚  â”œâ”€â”€ Natural language queries across all documents                      â”‚
â”‚  â”œâ”€â”€ Semantic search with filters                                       â”‚
â”‚  â””â”€â”€ Citations/sources for transparency                                 â”‚
â”‚                                                                         â”‚
â”‚  ML/Data Science:                                                        â”‚
â”‚  â”œâ”€â”€ Use LLM-extracted features in predictive models                   â”‚
â”‚  â”œâ”€â”€ Anomaly detection (unusual contract terms)                        â”‚
â”‚  â””â”€â”€ Clustering / similarity analysis                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GOVERNANCE & OBSERVABILITY LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Governance (Purview):                                             â”‚
â”‚  â”œâ”€â”€ Data lineage (source â†’ processed â†’ consumed)                      â”‚
â”‚  â”œâ”€â”€ Catalog (what data exists, where)                                 â”‚
â”‚  â””â”€â”€ PII/sensitivity classification                                     â”‚
â”‚                                                                         â”‚
â”‚  Monitoring (App Insights + Log Analytics):                             â”‚
â”‚  â”œâ”€â”€ Pipeline success/failure rates                                     â”‚
â”‚  â”œâ”€â”€ LLM latency, cost per document                                     â”‚
â”‚  â”œâ”€â”€ Data quality metrics (completeness, accuracy)                     â”‚
â”‚  â””â”€â”€ Drift detection (model performance over time)                      â”‚
â”‚                                                                         â”‚
â”‚  Security (Entra ID + Key Vault + Private Endpoints):                   â”‚
â”‚  â”œâ”€â”€ Authentication & authorization                                     â”‚
â”‚  â”œâ”€â”€ Secrets management (API keys, connection strings)                 â”‚
â”‚  â””â”€â”€ Network isolation (VNet, private endpoints)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key LLM Concepts for Data Science Teams

### 1. **Chunking** (Breaking Documents into Processable Units)

**Why it matters for large-scale data:**
- LLMs have token limits (4K-128K tokens depending on model)
- Large documents (contracts, reports) must be split
- Chunks become the unit of retrieval in RAG

**Your Implementation:**
```python
# Text chunking strategy
chunk_size = 1000 characters
overlap = 200 characters  # Context continuity

# Example:
Document (10,000 chars)
  â†’ Chunk 1: chars 0-1000
  â†’ Chunk 2: chars 800-1800 (overlap 800-1000)
  â†’ Chunk 3: chars 1600-2600 (overlap 1600-1800)
  â†’ ... (10 chunks total)

Each chunk:
  - Small enough to process
  - Maintains context via overlap
  - Searchable independently
  - Traceable back to source document
```

**ğŸ“„ See the Code:**
- **File:** `src/rag_system.py`
- **Function:** `chunk_text()` (lines 40-67)
- **Usage:** `add_contract_to_vectordb()` (line 85)

```python
# src/rag_system.py - lines 40-67
def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
    """Split text into overlapping chunks."""
    chunks = []
    start = 0
    text_length = len(text)
    
    while start < text_length:
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start += (chunk_size - overlap)  # Overlap maintains context
    
    return chunks

# Usage at line 85:
chunks = self.chunk_text(contract_text, chunk_size=3000, overlap=500)
```

**Data Science Perspective:**
> "Chunking is like data preprocessingâ€”we're breaking unstructured text into structured units that can be indexed, searched, and analyzed. It's similar to tokenization in NLP, but at the paragraph/section level for retrieval purposes."

---

### 2. **Vectorization / Embeddings** (Text â†’ Numerical Representation)

**Why it matters:**
- Enables semantic similarity search (not just keyword matching)
- Allows "distance" calculations between pieces of text
- Foundation for RAG retrieval

**Your Implementation:**
```python
# Embedding generation
text_chunk = "This contract expires on December 31, 2025..."
embedding = embedding_model.embed(text_chunk)
# Result: [0.234, -0.123, 0.891, ..., 0.456]  # 768 or 1536 dimensions

# Store in vector database
vector_db.insert({
    "chunk_id": "contract_123_chunk_5",
    "text": text_chunk,
    "embedding": embedding,
    "metadata": {"contract_id": 123, "risk": "high", "party": "Acme Corp"}
})
```

**ğŸ“„ See the Code:**
- **File:** `src/rag_system.py`
- **Function:** `add_contract_to_vectordb()` (lines 69-94)
- **Note:** Currently using simplified in-memory storage; in production, embeddings would be generated via Azure OpenAI or similar

```python
# src/rag_system.py - lines 69-94
async def add_contract_to_vectordb(
    self,
    contract_id: int,
    contract_text: str,
    contract_metadata: Dict[str, Any]
):
    """Add a contract to storage for search. Chunks the contract for better retrieval."""
    # Step 1: Chunk the contract
    chunks = self.chunk_text(contract_text, chunk_size=3000, overlap=500)
    
    # Step 2: Store contract with chunks (embeddings would be generated here in production)
    self.contracts_storage[contract_id] = {
        "text": contract_text,
        "chunks": chunks,  # Each chunk would have an embedding
        "metadata": contract_metadata
    }
```

**Key Technical Details:**
- **Embedding dimensions**: 768 (Azure OpenAI ada-002), 1536 (text-embedding-3-large)
- **Similarity metric**: Cosine similarity (most common for text)
- **Vector database**: Azure AI Search, Pinecone, Weaviate, Qdrant

**Data Science Perspective:**
> "Embeddings are feature engineering for textâ€”we're converting words into dense vectors that capture semantic meaning. Similar concepts cluster together in vector space, enabling similarity-based retrieval. It's like word2vec or sentence transformers but at scale for entire document corpora."

---

### 3. **Semantic Search** (Finding by Meaning, Not Keywords)

**Why it's better than keyword search:**
```
User Query: "contracts expiring soon with high penalties"

Keyword Search (SQL LIKE / full-text search):
âŒ Misses: "agreement terminating next quarter"
âŒ Misses: "substantial damages upon breach"
âŒ Only finds exact word matches

Semantic Search (Vector similarity):
âœ… Finds: "termination date approaching"
âœ… Finds: "significant financial consequences"
âœ… Understands intent, not just words
```

**Your Implementation Flow:**
```python
# Semantic search pipeline
1. User question â†’ embedding_model.embed(question)
2. Vector search: find top-K most similar chunks
3. Apply filters: risk_level='high', end_date < 90 days
4. Return ranked results with metadata
```

**ğŸ“„ See the Code:**
- **File:** `src/rag_system.py`
- **Function:** `search_contracts()` (lines 148-236)

```python
# src/rag_system.py - lines 148-236
def search_contracts(self, query: str, n_results: int = 5, contract_id: int = None):
    """Search across contracts using enhanced keyword matching on chunks."""
    
    # Semantic keyword expansion for better matching
    semantic_expansions = {
        'date': ['date', 'effective', 'execution', 'commence', 'start', 'end', ...],
        'payment': ['payment', 'fee', 'cost', 'price', 'invoice', ...],
        'termination': ['termination', 'terminate', 'cancel', ...],
        # ... more semantic mappings
    }
    
    # Expand keywords based on semantic mappings
    expanded_keywords = set(keywords)
    for keyword in keywords:
        for key, values in semantic_expansions.items():
            if keyword in values or keyword == key:
                expanded_keywords.update(values)
    
    # Score chunks based on keyword + semantic matches
    for chunk in chunks:
        original_score = sum(chunk.count(keyword) * 3 for keyword in keywords)
        expanded_score = sum(chunk.count(keyword) for keyword in expanded_keywords)
        total_score = original_score + expanded_score
```

**Data Science Perspective:**
> "Semantic search solves the vocabulary mismatch problemâ€”users ask questions in their own words, but documents use different terminology. Vector similarity handles synonyms, paraphrasing, and conceptual matches that keyword search misses. It's a game-changer for search over large document corpora."

---

### 4. **RAG (Retrieval Augmented Generation)** - The Core Pattern

**What RAG solves:**
- LLMs without RAG: hallucinate facts, no grounding, outdated knowledge
- LLMs with RAG: answer only from retrieved documents, cite sources, current data

**Your RAG Pipeline:**
```
User Question: "What are the SLA penalties in contracts with Microsoft?"

Step 1: RETRIEVAL
â”œâ”€â”€ Embed question â†’ [0.234, -0.123, ...]
â”œâ”€â”€ Search vector DB: top 5 most relevant chunks
â””â”€â”€ Results: 5 contract clauses about SLA penalties

Step 2: AUGMENTATION
â”œâ”€â”€ Construct prompt:
â”‚   "Context: [5 retrieved clauses]
â”‚    Question: What are the SLA penalties in contracts with Microsoft?
â”‚    Instructions: Answer only from context. Cite sources."
â”‚
â””â”€â”€ Send to LLM

Step 3: GENERATION
â”œâ”€â”€ LLM generates answer based on retrieved context
â”œâ”€â”€ Answer includes citations (contract IDs, clause numbers)
â””â”€â”€ No hallucinations (constrained to retrieved text)
```

**ğŸ“„ See the Code:**
- **File:** `src/rag_system.py`
- **Function:** `answer_question()` (lines 632-730)
- **Usage:** Called from `src/main.py` (line 741)

```python
# src/rag_system.py - lines 632-730
async def answer_question(self, question: str, contract_id: int = None) -> str:
    """Answer questions about contracts using RAG."""
    
    # Step 1: RETRIEVAL - Search for relevant chunks
    search_results = self.search_contracts(
        query=question,
        n_results=5,
        contract_id=contract_id
    )
    relevant_chunks = search_results.get('documents', [[]])[0]
    
    if not relevant_chunks:
        return "I couldn't find relevant information in the contracts."
    
    # Combine chunks for context
    context = "\n\n---\n\n".join(relevant_chunks)
    
    # Step 2 & 3: AUGMENTATION + GENERATION
    prompt = f"""
    You are a helpful contract management assistant.
    
    Based on the following contract excerpts, answer the user's question.
    
    IMPORTANT: Answer only from the provided context.
    
    Contract Excerpts:
    {context}
    
    User Question: {question}
    
    Answer:
    """
    
    response = self.model.generate_content(prompt)  # LLM call
    return response.text
```

**Why RAG is critical for enterprise:**
- **Accuracy**: Answers grounded in actual data
- **Transparency**: Citations enable verification
- **Privacy**: Sensitive data never in training, only at query time
- **Freshness**: Works with real-time/current documents

**Data Science Perspective:**
> "RAG is like a SQL query followed by summarizationâ€”we retrieve relevant records (chunks) based on similarity, then use an LLM to synthesize an answer. It's the bridge between unstructured text and natural language Q&A, making document corpora queryable like databases."

---

### 5. **Structured Extraction** (Unstructured â†’ Structured Data)

**The data science value proposition:**
```python
# Input: Unstructured PDF (contract)
contract_pdf = """
  AGREEMENT between Acme Corp and Beta Inc.
  Effective date: January 15, 2024
  Contract value: $250,000 USD
  Payment terms: Net 30
  ...5000 more words...
"""

# LLM prompt (structured output)
prompt = """
Extract the following fields as JSON:
- contract_number
- party_a
- party_b
- start_date
- end_date
- contract_value
- currency
- risk_level (low/medium/high/critical)
- risk_reason
"""

# Output: Structured JSON â†’ SQL table
{
  "contract_number": "CNT-2024-1015",
  "party_a": "Acme Corp",
  "party_b": "Beta Inc",
  "start_date": "2024-01-15",
  "end_date": "2025-01-14",
  "contract_value": 250000,
  "currency": "USD",
  "risk_level": "medium",
  "risk_reason": "Contract value moderate with standard terms"
}

# Now queryable in SQL:
SELECT AVG(contract_value), COUNT(*)
FROM contracts
WHERE risk_level = 'high' AND party_a = 'Acme Corp'
GROUP BY party_a;
```

**ğŸ“„ See the Code:**
- **Metadata Extraction:** `src/rag_system.py`, function `extract_contract_metadata()` (lines 366-480)
- **Risk Assessment:** `src/rag_system.py`, function `assess_risk_level()` (lines 482-630)
- **Summarization:** `src/rag_system.py`, function `generate_contract_summary()` (lines 238-325)
- **Usage:** `src/main.py`, upload endpoint (lines 560, 569, 587)

```python
# src/rag_system.py - lines 366-480 (extract_contract_metadata)
async def extract_contract_metadata(self, contract_text: str) -> Dict[str, Any]:
    """Extract structured metadata from contract using AI."""
    
    prompt = f"""
    You are a contract metadata extractor. Extract key information.
    
    Return ONLY a valid JSON object with these exact fields:
    {{
        "contract_name": "type of agreement",
        "contract_number": "contract number or ID",
        "party_a": "first party name",
        "party_b": "second party name", 
        "start_date": "YYYY-MM-DD format",
        "end_date": "YYYY-MM-DD format",
        "contract_value": numeric value or null,
        "currency": "USD or other currency code"
    }}
    
    Contract Text:
    {contract_text}
    """
    
    response = self.model.generate_content(prompt)
    metadata = json.loads(response.text)  # Parse JSON output
    return metadata

# src/main.py - lines 560, 569, 587 (usage in upload)
metadata = await rag_system.extract_contract_metadata(contract_text)
summary = await rag_system.generate_contract_summary(contract_text)
risk_assessment = await rag_system.assess_risk_level(contract_text)
```

**Data Quality Considerations:**
- Validation: date formats, currency codes, value ranges
- Confidence scoring: flag low-confidence extractions for review
- Human-in-the-loop: 10% sample review for accuracy monitoring
- Schema versioning: track prompt changes and output formats

**Data Science Perspective:**
> "This is like automated feature engineering for unstructured dataâ€”we're creating structured columns from free text that can be used in analytics, ML models, and BI dashboards. It's ETL where the 'T' (transform) is powered by an LLM instead of regex or rules."

---

## How ADF Fits in Data Science Workflows

### ADF's Role (Orchestration, Not Computation)

**What ADF Does:**
- **Schedule** LLM processing pipelines (daily batch, hourly micro-batch)
- **Coordinate** multi-source ingestion (SharePoint, SQL, APIs â†’ ADLS)
- **Trigger** compute layers (Azure Functions, AKS jobs, Databricks notebooks)
- **Monitor** pipeline health (retries, alerts, logging)
- **Manage** dependencies (process contracts after vendors sync)

**What ADF Does NOT Do:**
- Run LLM inference (too heavy, wrong tool)
- Store large vectors (use Azure AI Search instead)
- Complex transformations (use Databricks/Functions)

**ADF Pipeline Example: LLM Document Processing**
```
Pipeline: Process_New_Contracts

1. Lookup Activity: Query Azure SQL
   - Find contracts with status = 'uploaded'
   - Return array of contract IDs

2. ForEach Activity: Loop over contract IDs
   
   2a. Azure Function Activity: /extract-text
       - Input: contract_id
       - Output: extracted text â†’ ADLS

   2b. Azure Function Activity: /process-with-llm
       - Input: contract_id, text
       - Output: structured JSON â†’ Azure SQL

   2c. Azure Function Activity: /embed-and-index
       - Input: contract_id, text
       - Output: vectors â†’ Azure AI Search

   2d. Update Activity: Mark processed
       - Update Azure SQL: status = 'processed'

3. On Failure:
   - Mark status = 'failed'
   - Log error to App Insights
   - Alert data team

4. Success Metrics:
   - Log processing time, cost
   - Track data quality scores
```

---

## Responsible AI for Data Science Teams

### Why it matters for Microsoft interviews:
Microsoft emphasizes **Responsible AI** heavily. Show you understand:

1. **Data Privacy:**
   - PII redaction before LLM processing
   - Data residency (keep sensitive data in region)
   - Access controls (RBAC, row-level security)

2. **Bias & Fairness:**
   - Monitor extraction accuracy across document types
   - Avoid biased risk assessments (don't penalize small companies)
   - Regular audits of classification outputs

3. **Transparency:**
   - Explainable outputs (why this risk level?)
   - Citations in RAG (which document chunk?)
   - Prompt versioning (track what instructions were used)

4. **Accountability:**
   - Human review for high-stakes decisions
   - Audit logs (who accessed, what was changed)
   - Model performance monitoring (drift detection)

5. **Reliability:**
   - Hallucination detection (did LLM make up facts?)
   - Confidence thresholds (flag uncertain extractions)
   - Fallback mechanisms (if LLM fails, use rules)

**Interview Sound Bite:**
> "I designed this system with responsible AI principlesâ€”all high-risk classifications get human review, we log prompts and outputs for audit, use RAG to prevent hallucinations, and monitor for data quality and bias. It's not just about accuracy; it's about building trust and ensuring compliance."

---

## Real-Time vs Batch Processing (Data Architecture Decision)

### Batch Processing (Most Common for Large Data Volumes)
```
Use Case: Process 100,000 historical contracts

Architecture:
â”œâ”€â”€ Daily ADF pipeline (midnight)
â”œâ”€â”€ Batch process 10,000 docs/day
â”œâ”€â”€ Cost-optimized (non-peak hours)
â””â”€â”€ Tolerate 12-24 hour latency

Benefits:
âœ… Cost-effective ($0.01-0.05 per doc)
âœ… Handles large volumes
âœ… Predictable resource usage
âœ… Easy to monitor/debug
```

### Real-Time Processing (For Low-Latency Use Cases)
```
Use Case: Process contracts as soon as uploaded

Architecture:
â”œâ”€â”€ Event Grid trigger (file upload)
â”œâ”€â”€ Azure Function picks up event
â”œâ”€â”€ Process within seconds-minutes
â””â”€â”€ Results available immediately

Benefits:
âœ… Instant insights
âœ… Better user experience
âœ… Enable real-time workflows

Challenges:
âš ï¸ Higher cost per doc
âš ï¸ Requires scalable infrastructure
âš ï¸ More complex monitoring
```

**Hybrid Approach (Best of Both):**
```
Real-time: High-priority docs (new contracts, urgent requests)
Batch: Bulk processing (historical backfill, analytics updates)
```

---

## Interview-Ready Talking Points

### 30-Second Pitch
> "I built an LLM-powered data pipeline that turns unstructured contracts into structured, queryable data. I use **chunking** to break documents into searchable units, **embeddings** to enable semantic search, and **RAG** to provide accurate Q&A with citations. The structured data integrates with existing SQL databases, enabling analytics and ML. I designed it with responsible AI principlesâ€”human oversight, audit trails, and bias monitoring. In a Microsoft context, I'd orchestrate this with ADF, use Azure AI Search for vector storage, and either Azure OpenAI or open-source models on AKS for LLM inference."

### Key Concepts to Emphasize
1. **LLMs as Data Processing Tools** (not just chatbots)
2. **RAG reduces hallucinations** (critical for enterprise trust)
3. **Vector search unlocks semantic retrieval** (better than keyword)
4. **Structured extraction creates SQL-queryable data** (integrates with existing pipelines)
5. **Responsible AI is non-negotiable** (privacy, bias, transparency)
6. **ADF orchestrates, compute executes** (right tool for each job)

### Questions to Ask Them
1. "What types of unstructured data do you currently have that aren't being analyzed?"
2. "Are you using Azure OpenAI or exploring open-source models?"
3. "How do you currently handle document search and retrieval?"
4. "What's your data governance approach for PII in unstructured data?"
5. "Are you more interested in batch analytics or real-time insights?"

---

## Microsoft Service Stack (Complete Mapping)

| Function | Azure Service | Your Implementation |
|----------|---------------|---------------------|
| **Data Ingestion** | ADF, Event Grid | File uploads, SharePoint sync |
| **Data Storage** | ADLS Gen2, Azure SQL | Raw files + structured metadata |
| **Text Extraction** | Azure Functions, AI Vision (OCR) | PDF â†’ text pipeline |
| **LLM Inference** | Azure OpenAI / AKS + vLLM | Extraction, summarization, classification |
| **Embeddings** | Azure OpenAI (ada-002, text-embedding-3) | Text â†’ vectors |
| **Vector Search** | Azure AI Search | Semantic retrieval, RAG |
| **Orchestration** | ADF, Synapse Pipelines | Scheduling, dependencies |
| **Analytics** | Synapse, Fabric, Power BI | SQL queries, dashboards |
| **Monitoring** | App Insights, Log Analytics | Metrics, logs, alerts |
| **Security** | Entra ID, Key Vault, Private Endpoints | Auth, secrets, network isolation |
| **Governance** | Purview | Lineage, catalog, PII classification |

---

## Your Competitive Advantage

**What makes you valuable:**
1. âœ… **Hands-on LLM integration** (not just theory)
2. âœ… **Data engineering mindset** (pipelines, quality, scale)
3. âœ… **Responsible AI awareness** (governance, bias, privacy)
4. âœ… **Multi-source integration experience** (real-world complexity)
5. âœ… **Production-ready thinking** (monitoring, retries, cost)

**Your Story:**
> "Data teams often have a goldmine of unstructured data that's underutilized. I saw this problem with contractsâ€”they contained critical business information, but it was locked in PDFs. I built an LLM pipeline that extracts structured metadata, enables semantic search via RAG, and integrates with existing data infrastructure. Now contracts are queryable like any other dataset, and we can do analytics, ML, and natural language Q&A. That's the kind of LLM-for-data-science thinking I'd bring to your team."

---

**Good luck with your Microsoft interview! ğŸš€**

*Focus on: data integration, scale, responsible AI, and real-world production concernsâ€”that's what data science teams care about.*
